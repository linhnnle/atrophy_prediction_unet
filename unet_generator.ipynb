{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type bytes)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 23\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmonai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m ArrayDataset, CacheDataset\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmonai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     Activations,\n\u001b[1;32m     14\u001b[0m     EnsureChannelFirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     ScaleIntensity,\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransform\u001b[39;00m \u001b[39mimport\u001b[39;00m resize\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/__init__.py:64\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[39m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __check_build\n\u001b[0;32m---> 64\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m clone\n\u001b[1;32m     65\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_show_versions\u001b[39;00m \u001b[39mimport\u001b[39;00m show_versions\n\u001b[1;32m     67\u001b[0m     __check_build  \u001b[39m# avoid flakes unused variable error\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/base.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m \u001b[39mimport\u001b[39;00m sparse\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexternals\u001b[39;00m \u001b[39mimport\u001b[39;00m six\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfixes\u001b[39;00m \u001b[39mimport\u001b[39;00m signature\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _IS_32BIT\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/utils/__init__.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmurmurhash\u001b[39;00m \u001b[39mimport\u001b[39;00m murmurhash3_32\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mclass_weight\u001b[39;00m \u001b[39mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _joblib\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m DataConversionWarning\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfixes\u001b[39;00m \u001b[39mimport\u001b[39;00m _Sequence \u001b[39mas\u001b[39;00m Sequence\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/utils/_joblib.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mjoblib\u001b[39;00m \u001b[39mimport\u001b[39;00m parallel_backend, register_parallel_backend\n\u001b[1;32m     21\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexternals\u001b[39;00m \u001b[39mimport\u001b[39;00m joblib\n\u001b[1;32m     23\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexternals\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mjoblib\u001b[39;00m \u001b[39mimport\u001b[39;00m logger\n\u001b[1;32m     24\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexternals\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mjoblib\u001b[39;00m \u001b[39mimport\u001b[39;00m dump, load\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:119\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnumpy_pickle\u001b[39;00m \u001b[39mimport\u001b[39;00m load\n\u001b[1;32m    118\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcompressor\u001b[39;00m \u001b[39mimport\u001b[39;00m register_compressor\n\u001b[0;32m--> 119\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mparallel\u001b[39;00m \u001b[39mimport\u001b[39;00m Parallel\n\u001b[1;32m    120\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mparallel\u001b[39;00m \u001b[39mimport\u001b[39;00m delayed\n\u001b[1;32m    121\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mparallel\u001b[39;00m \u001b[39mimport\u001b[39;00m cpu_count\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/externals/joblib/parallel.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmy_exceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m TransportableException\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdisk\u001b[39;00m \u001b[39mimport\u001b[39;00m memstr_to_bytes\n\u001b[0;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_parallel_backends\u001b[39;00m \u001b[39mimport\u001b[39;00m (FallbackToBackend, MultiprocessingBackend,\n\u001b[1;32m     29\u001b[0m                                  ThreadingBackend, SequentialBackend,\n\u001b[1;32m     30\u001b[0m                                  LokyBackend)\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_compat\u001b[39;00m \u001b[39mimport\u001b[39;00m _basestring\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexternals\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcloudpickle\u001b[39;00m \u001b[39mimport\u001b[39;00m dumps, loads\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/externals/joblib/_parallel_backends.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpool\u001b[39;00m \u001b[39mimport\u001b[39;00m MemmappingPool\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmultiprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpool\u001b[39;00m \u001b[39mimport\u001b[39;00m ThreadPool\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexecutor\u001b[39;00m \u001b[39mimport\u001b[39;00m get_memmapping_executor\n\u001b[1;32m     24\u001b[0m \u001b[39m# Compat between concurrent.futures and multiprocessing TimeoutError\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmultiprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/externals/joblib/executor.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdisk\u001b[39;00m \u001b[39mimport\u001b[39;00m delete_folder\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_memmapping_reducer\u001b[39;00m \u001b[39mimport\u001b[39;00m get_memmapping_reducers\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexternals\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mloky\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreusable_executor\u001b[39;00m \u001b[39mimport\u001b[39;00m get_reusable_executor\n\u001b[1;32m     17\u001b[0m _backend_args \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_memmapping_executor\u001b[39m(n_jobs, timeout\u001b[39m=\u001b[39m\u001b[39m300\u001b[39m, initializer\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, initargs\u001b[39m=\u001b[39m(),\n\u001b[1;32m     21\u001b[0m                             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbackend_args):\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/externals/joblib/externals/loky/__init__.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_base\u001b[39;00m \u001b[39mimport\u001b[39;00m ALL_COMPLETED, FIRST_COMPLETED, FIRST_EXCEPTION\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontext\u001b[39;00m \u001b[39mimport\u001b[39;00m cpu_count\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreduction\u001b[39;00m \u001b[39mimport\u001b[39;00m set_loky_pickler\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mreusable_executor\u001b[39;00m \u001b[39mimport\u001b[39;00m get_reusable_executor\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcloudpickle_wrapper\u001b[39;00m \u001b[39mimport\u001b[39;00m wrap_non_picklable_objects\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/externals/joblib/externals/loky/backend/reduction.py:125\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39m# global variable to change the pickler behavior\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexternals\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mjoblib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexternals\u001b[39;00m \u001b[39mimport\u001b[39;00m cloudpickle  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     DEFAULT_ENV \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcloudpickle\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[39m# If cloudpickle is not present, fallback to pickle\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/externals/joblib/externals/cloudpickle/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m absolute_import\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcloudpickle\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      5\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m0.6.1\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:167\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m         \u001b[39mreturn\u001b[39;00m types\u001b[39m.\u001b[39mCodeType(\n\u001b[1;32m    149\u001b[0m             co\u001b[39m.\u001b[39mco_argcount,\n\u001b[1;32m    150\u001b[0m             co\u001b[39m.\u001b[39mco_kwonlyargcount,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m             (),\n\u001b[1;32m    164\u001b[0m         )\n\u001b[0;32m--> 167\u001b[0m _cell_set_template_code \u001b[39m=\u001b[39m _make_cell_set_template_code()\n\u001b[1;32m    170\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcell_set\u001b[39m(cell, value):\n\u001b[1;32m    171\u001b[0m     \u001b[39m\"\"\"Set the value of a closure cell.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:148\u001b[0m, in \u001b[0;36m_make_cell_set_template_code\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[39mreturn\u001b[39;00m types\u001b[39m.\u001b[39mCodeType(\n\u001b[1;32m    132\u001b[0m         co\u001b[39m.\u001b[39mco_argcount,\n\u001b[1;32m    133\u001b[0m         co\u001b[39m.\u001b[39mco_nlocals,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    145\u001b[0m         (),\n\u001b[1;32m    146\u001b[0m     )\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 148\u001b[0m     \u001b[39mreturn\u001b[39;00m types\u001b[39m.\u001b[39;49mCodeType(\n\u001b[1;32m    149\u001b[0m         co\u001b[39m.\u001b[39;49mco_argcount,\n\u001b[1;32m    150\u001b[0m         co\u001b[39m.\u001b[39;49mco_kwonlyargcount,\n\u001b[1;32m    151\u001b[0m         co\u001b[39m.\u001b[39;49mco_nlocals,\n\u001b[1;32m    152\u001b[0m         co\u001b[39m.\u001b[39;49mco_stacksize,\n\u001b[1;32m    153\u001b[0m         co\u001b[39m.\u001b[39;49mco_flags,\n\u001b[1;32m    154\u001b[0m         co\u001b[39m.\u001b[39;49mco_code,\n\u001b[1;32m    155\u001b[0m         co\u001b[39m.\u001b[39;49mco_consts,\n\u001b[1;32m    156\u001b[0m         co\u001b[39m.\u001b[39;49mco_names,\n\u001b[1;32m    157\u001b[0m         co\u001b[39m.\u001b[39;49mco_varnames,\n\u001b[1;32m    158\u001b[0m         co\u001b[39m.\u001b[39;49mco_filename,\n\u001b[1;32m    159\u001b[0m         co\u001b[39m.\u001b[39;49mco_name,\n\u001b[1;32m    160\u001b[0m         co\u001b[39m.\u001b[39;49mco_firstlineno,\n\u001b[1;32m    161\u001b[0m         co\u001b[39m.\u001b[39;49mco_lnotab,\n\u001b[1;32m    162\u001b[0m         co\u001b[39m.\u001b[39;49mco_cellvars,  \u001b[39m# this is the trickery\u001b[39;49;00m\n\u001b[1;32m    163\u001b[0m         (),\n\u001b[1;32m    164\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required (got type bytes)"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from distutils.command.config import config\n",
    "import pathlib\n",
    "import torch\n",
    "\n",
    "# import albumentations\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from monai.data import ArrayDataset, CacheDataset\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    EnsureChannelFirst,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandSpatialCrop,\n",
    "    Resize,\n",
    "    ScaleIntensity,\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage.transform import resize\n",
    "# from customdatasets import SegmentationDataSet1\n",
    "from transformation import (\n",
    "    ComposeDouble,\n",
    "    AlbuSeg3d,\n",
    "    FunctionWrapperDouble,\n",
    "    normalize_01,\n",
    "    create_dense_target,\n",
    ")\n",
    "from unet import UNet\n",
    "from trainer import Trainer\n",
    "from dataset import AtrophyDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/linhle/Documents/UC_Davis/Fan_Lab/atrophyData/NewJacs/NIFTI/10100_042903_091316_2.0_ONLM_Jac_Warped_Annualized_MDT3_mask.nii', '/Users/linhle/Documents/UC_Davis/Fan_Lab/atrophyData/NewJacs/NIFTI/2353_112712_111513_2.0_ONLM_Jac_Warped_Annualized_MDT3_mask.nii', '/Users/linhle/Documents/UC_Davis/Fan_Lab/atrophyData/NewJacs/NIFTI/2369_100709_112613_2.0_ONLM_Jac_Warped_Annualized_MDT3_mask.nii', '/Users/linhle/Documents/UC_Davis/Fan_Lab/atrophyData/NewJacs/NIFTI/2448_072407_112013_2.0_ONLM_Jac_Warped_Annualized_MDT3_mask.nii', '/Users/linhle/Documents/UC_Davis/Fan_Lab/atrophyData/NewJacs/NIFTI/2524_021804_082516_2.0_ONLM_Jac_Warped_Annualized_MDT3_mask.nii', '/Users/linhle/Documents/UC_Davis/Fan_Lab/atrophyData/NewJacs/NIFTI/2580_051904_051316_2.0_ONLM_Jac_Warped_Annualized_MDT3_mask.nii', '/Users/linhle/Documents/UC_Davis/Fan_Lab/atrophyData/NewJacs/NIFTI/2771_120909_093016_2.0_ONLM_Jac_Warped_Annualized_MDT3_mask.nii', '/Users/linhle/Documents/UC_Davis/Fan_Lab/atrophyData/NewJacs/NIFTI/2808_110805_060914_2.0_ONLM_Jac_Warped_Annualized_MDT3_mask.nii', '/Users/linhle/Documents/UC_Davis/Fan_Lab/atrophyData/NewJacs/NIFTI/2829_042409_090911_2.0_ONLM_Jac_Warped_Annualized_MDT3_mask.nii', '/Users/linhle/Documents/UC_Davis/Fan_Lab/atrophyData/NewJacs/NIFTI/2851_072106_030416_2.0_ONLM_Jac_Warped_Annualized_MDT3_mask.nii']\n"
     ]
    }
   ],
   "source": [
    "# root directory\n",
    "# root = pathlib.Path.cwd() / \"Carvana\"\n",
    "root = \"/Users/linhle/Documents/UC_Davis/Fan_Lab/atrophyData/\"\n",
    "\n",
    "\n",
    "def get_filenames_of_path(path: pathlib.Path, ext: str = \"*\"):\n",
    "    \"\"\"Returns a list of files in a directory/path. Uses pathlib.\"\"\"\n",
    "    filenames = [file for file in path.glob(ext) if file.is_file()]\n",
    "    return filenames\n",
    "\n",
    "inputs = sorted(glob.glob(os.path.join(root,\"trainData/NIFTI/\", \"*3DT1_Warped.nii\")))\n",
    "targets = sorted(glob.glob(os.path.join(root,\"NewJacs/NIFTI/\", \"*MDT3_mask.nii\")))\n",
    "\n",
    "\n",
    "# input and target files\n",
    "# inputs = get_filenames_of_path(root / \"trainData\")\n",
    "# targets = get_filenames_of_path(root / \"NewJacs\")\n",
    "\n",
    "print(targets[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training transformations and augmentations\n",
    "'''\n",
    "transforms_training = ComposeDouble(\n",
    "    [\n",
    "        FunctionWrapperDouble(\n",
    "            resize, input=True, target=False, output_shape=(128, 128, 3)\n",
    "        ),\n",
    "        FunctionWrapperDouble(\n",
    "            resize,\n",
    "            input=False,\n",
    "            target=True,\n",
    "            output_shape=(128, 128),\n",
    "            order=0,\n",
    "            anti_aliasing=False,\n",
    "            preserve_range=True,\n",
    "        ),\n",
    "        AlbuSeg2d(albumentations.HorizontalFlip(p=0.5)),\n",
    "        FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "        FunctionWrapperDouble(\n",
    "            np.moveaxis, input=True, target=False, source=-1, destination=0\n",
    "        ),\n",
    "        FunctionWrapperDouble(normalize_01),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# validation transformations\n",
    "transforms_validation = ComposeDouble(\n",
    "    [\n",
    "        FunctionWrapperDouble(\n",
    "            resize, input=True, target=False, output_shape=(128, 128, 3)\n",
    "        ),\n",
    "        FunctionWrapperDouble(\n",
    "            resize,\n",
    "            input=False,\n",
    "            target=True,\n",
    "            output_shape=(128, 128),\n",
    "            order=0,\n",
    "            anti_aliasing=False,\n",
    "            preserve_range=True,\n",
    "        ),\n",
    "        FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "        FunctionWrapperDouble(\n",
    "            np.moveaxis, input=True, target=False, source=-1, destination=0\n",
    "        ),\n",
    "        FunctionWrapperDouble(normalize_01),\n",
    "    ]\n",
    ")\n",
    "'''\n",
    "# transforms_training = Compose(\n",
    "#     [\n",
    "#         LoadImage(image_only=True),\n",
    "#         ScaleIntensity(),\n",
    "#         EnsureChannelFirst(),\n",
    "#         # RandSpatialCrop((128, 96, 128), random_size=False),\n",
    "#     ]\n",
    "# )\n",
    "# transforms_target = Compose(\n",
    "#     [\n",
    "#         LoadImage(image_only=True),\n",
    "#         EnsureChannelFirst(),\n",
    "#         # RandSpatialCrop((128, 96, 128), random_size=False),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# training transformations and augmentations\n",
    "transforms_training = ComposeDouble([\n",
    "    # AlbuSeg3d(albumentations.HorizontalFlip(p=0.5)),\n",
    "    FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "    FunctionWrapperDouble(np.moveaxis, input=True, target=False, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01)\n",
    "])\n",
    "\n",
    "# validation transformations\n",
    "transforms_validation = ComposeDouble([\n",
    "    FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "    FunctionWrapperDouble(np.moveaxis, input=True, target=False, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01)\n",
    "])\n",
    "\n",
    "pre_transforms = ComposeDouble([\n",
    "    FunctionWrapperDouble(resize,\n",
    "                          input=True,\n",
    "                          target=False,\n",
    "                          output_shape=(128, 96, 128)),\n",
    "    FunctionWrapperDouble(resize,\n",
    "                          input=False,\n",
    "                          target=True,\n",
    "                          output_shape=(128, 96, 128),\n",
    "                        #   order=0,\n",
    "                          anti_aliasing=False,\n",
    "                          preserve_range=True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching: 100%|██████████| 74/74 [00:11<00:00,  6.47it/s]\n",
      "Caching: 100%|██████████| 19/19 [00:02<00:00,  7.08it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# random seed\n",
    "random_seed = 42\n",
    "\n",
    "# split dataset into training set and validation set\n",
    "train_size = 0.8  # 80:20 split\n",
    "\n",
    "inputs_train, inputs_valid = train_test_split(\n",
    "    inputs, random_state=random_seed, train_size=train_size, shuffle=True\n",
    ")\n",
    "\n",
    "targets_train, targets_valid = train_test_split(\n",
    "    targets, random_state=random_seed, train_size=train_size, shuffle=True\n",
    ")\n",
    "\n",
    "# inputs_train, inputs_valid = inputs[:80], inputs[80:]\n",
    "# targets_train, targets_valid = targets[:80], targets[:80]\n",
    "\n",
    "# dataset training\n",
    "# dataset_train = ArrayDataset(\n",
    "#     inputs_train, transforms_training, targets_train, transforms_target\n",
    "# )\n",
    "\n",
    "\n",
    "dataset_train = AtrophyDataset(inputs=inputs_train,\n",
    "                                targets=targets_train,\n",
    "                                transform=transforms_training,\n",
    "                                use_cache=True,\n",
    "                                pre_transform=pre_transforms)\n",
    "\n",
    "# dataset validation\n",
    "# dataset_val = ArrayDataset(\n",
    "#     inputs_valid, transforms_training, targets_valid, transforms_training\n",
    "# )\n",
    "\n",
    "dataset_val = AtrophyDataset(inputs=inputs_valid,\n",
    "                                targets=targets_valid,\n",
    "                                transform=transforms_validation,\n",
    "                                use_cache=True,\n",
    "                                pre_transform=pre_transforms)\n",
    "\n",
    "# dataloader training\n",
    "dataloader_training = DataLoader(dataset=dataset_train, batch_size=8, shuffle=True)\n",
    "\n",
    "# dataloader validation\n",
    "dataloader_validation = DataLoader(dataset=dataset_val, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m i,j \u001b[39min\u001b[39;00m dataloader_training:\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mimage shape \u001b[39m\u001b[39m\"\u001b[39m, {i\u001b[39m.\u001b[39mshape})\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mlabel shape \u001b[39m\u001b[39m\"\u001b[39m, {j\u001b[39m.\u001b[39mshape})\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/GitHub/atrophy_prediction_unet/dataset.py:55\u001b[0m, in \u001b[0;36mAtrophyDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39m# Preprocessing\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m     x, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(x, y)\n\u001b[1;32m     57\u001b[0m \u001b[39m# Typecasting\u001b[39;00m\n\u001b[1;32m     58\u001b[0m x, y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(x)\u001b[39m.\u001b[39mtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs_dtype), torch\u001b[39m.\u001b[39mfrom_numpy(y)\u001b[39m.\u001b[39mtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets_dtype)\n",
      "File \u001b[0;32m~/Documents/GitHub/atrophy_prediction_unet/transformation.py:127\u001b[0m, in \u001b[0;36mComposeDouble.__call__\u001b[0;34m(self, inp, target)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, inp: np\u001b[39m.\u001b[39mndarray, target: \u001b[39mdict\u001b[39m):\n\u001b[1;32m    126\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m--> 127\u001b[0m         inp, target \u001b[39m=\u001b[39m t(inp, target)\n\u001b[1;32m    128\u001b[0m     \u001b[39mreturn\u001b[39;00m inp, target\n",
      "File \u001b[0;32m~/Documents/GitHub/atrophy_prediction_unet/transformation.py:108\u001b[0m, in \u001b[0;36mFunctionWrapperDouble.__call__\u001b[0;34m(self, inp, tar)\u001b[0m\n\u001b[1;32m    106\u001b[0m     inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(inp)\n\u001b[1;32m    107\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget:\n\u001b[0;32m--> 108\u001b[0m     tar \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(tar)\n\u001b[1;32m    109\u001b[0m \u001b[39mreturn\u001b[39;00m inp, tar\n",
      "File \u001b[0;32m~/Documents/GitHub/atrophy_prediction_unet/transformation.py:27\u001b[0m, in \u001b[0;36mcreate_dense_target\u001b[0;34m(tar)\u001b[0m\n\u001b[1;32m     25\u001b[0m dummy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros_like(tar)\n\u001b[1;32m     26\u001b[0m \u001b[39mfor\u001b[39;00m idx, value \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(classes):\n\u001b[0;32m---> 27\u001b[0m     mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mwhere(tar \u001b[39m==\u001b[39;49m value)\n\u001b[1;32m     28\u001b[0m     dummy[mask] \u001b[39m=\u001b[39m idx\n\u001b[1;32m     30\u001b[0m \u001b[39mreturn\u001b[39;00m dummy\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i,j in dataloader_training:\n",
    "    print(\"image shape \", {i.shape})\n",
    "    print(\"label shape \", {j.shape})\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DatasetViewer instances\n",
    "from visual import DatasetViewer\n",
    "\n",
    "dataset_viewer_training = DatasetViewer(dataset_train)\n",
    "dataset_viewer_validation = DatasetViewer(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [59], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# open napari instance for training dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# navigate with 'n' for next and 'b' for back on the keyboard\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m dataset_viewer_training\u001b[38;5;241m.\u001b[39mnapari()\n",
      "File \u001b[0;32m~/Documents/GitHub/atrophy_prediction_unet/visual.py:44\u001b[0m, in \u001b[0;36mDatasetViewer.napari\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mviewer \u001b[39m=\u001b[39m napari\u001b[39m.\u001b[39mViewer()\n\u001b[1;32m     43\u001b[0m \u001b[39m# Show current sample\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshow_sample()\n\u001b[1;32m     46\u001b[0m \u001b[39m# Key-bindings\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39m# Press 'n' to get the next sample\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[39m@self\u001b[39m\u001b[39m.\u001b[39mviewer\u001b[39m.\u001b[39mbind_key(\u001b[39m\"\u001b[39m\u001b[39mn\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnext\u001b[39m(viewer):\n",
      "File \u001b[0;32m~/Documents/GitHub/atrophy_prediction_unet/visual.py:78\u001b[0m, in \u001b[0;36mDatasetViewer.show_sample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m names \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_names_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m     77\u001b[0m x_name, y_name \u001b[39m=\u001b[39m names\n\u001b[0;32m---> 78\u001b[0m x_name, y_name \u001b[39m=\u001b[39m x_name\u001b[39m.\u001b[39;49mname, y_name\u001b[39m.\u001b[39mname  \u001b[39m# only possible if pathlib.Path\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39m# Transform the sample to numpy, cpu and correct format to visualize\u001b[39;00m\n\u001b[1;32m     81\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform_x(x)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "# open napari instance for training dataset\n",
    "# navigate with 'n' for next and 'b' for back on the keyboard\n",
    "dataset_viewer_training.napari()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open napari instance for validation dataset\n",
    "# navigate with 'n' for next and 'b' for back on the keyboard\n",
    "dataset_viewer_validation.napari()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# device (using GPU)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m\"\u001b[39m) \n\u001b[1;32m      3\u001b[0m \u001b[39m# if torch.cuda.is_available() else torch.device(\"cpu\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[39m# model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model \u001b[39m=\u001b[39m UNet(\n\u001b[1;32m      7\u001b[0m     in_channels\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m      8\u001b[0m     out_channels\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     dim\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m     15\u001b[0m )\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# device (using GPU)\n",
    "device = torch.device(\"mps\") \n",
    "# if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# model\n",
    "model = UNet(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    n_blocks=5,\n",
    "    start_filters=32,\n",
    "    activation=\"relu\",\n",
    "    normalization=\"batch\",\n",
    "    conv_mode=\"same\",\n",
    "    dim=3,\n",
    ").to(device)\n",
    "\n",
    "# criterion\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# optimizer\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "lr = 1e-2 # learning rate \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9706d9db4a449b8b9bb809fd3fb9837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83afbbef91344b89fc83782948b15fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 1, 3, 3, 3], expected input[1, 8, 128, 128, 4] to have 1 channels, but got 8 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [66], line 16\u001b[0m\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      4\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     notebook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# start training\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m training_losses, validation_losses, lr_rates \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mrun_trainer()\n",
      "File \u001b[0;32m~/Documents/GitHub/atrophy_prediction_unet/trainer.py:47\u001b[0m, in \u001b[0;36mTrainer.run_trainer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# epoch counter\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39m\"\"\"Training block\"\"\"\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train()\n\u001b[1;32m     49\u001b[0m \u001b[39m\"\"\"Validation block\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_DataLoader \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/GitHub/atrophy_prediction_unet/trainer.py:76\u001b[0m, in \u001b[0;36mTrainer._train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39minput\u001b[39m, target \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice), y\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)  \u001b[39m# send to device (GPU or CPU)\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()  \u001b[39m# zerograd the parameters\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39minput\u001b[39;49m)  \u001b[39m# one forward pass\u001b[39;00m\n\u001b[1;32m     77\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(out, target)  \u001b[39m# calculate loss\u001b[39;00m\n\u001b[1;32m     78\u001b[0m loss_value \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/atrophy_prediction_unet/unet.py:371\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39m# Encoder pathway\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown_blocks:\n\u001b[0;32m--> 371\u001b[0m     x, before_pooling \u001b[39m=\u001b[39m module(x)\n\u001b[1;32m    372\u001b[0m     encoder_output\u001b[39m.\u001b[39mappend(before_pooling)\n\u001b[1;32m    374\u001b[0m \u001b[39m# Decoder pathway\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/atrophy_prediction_unet/unet.py:175\u001b[0m, in \u001b[0;36mDownBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 175\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)  \u001b[39m# convolution 1\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact1(y)  \u001b[39m# activation 1\u001b[39;00m\n\u001b[1;32m    177\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalization:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/conv.py:613\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 613\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/conv.py:608\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    597\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv3d(\n\u001b[1;32m    598\u001b[0m         F\u001b[39m.\u001b[39mpad(\n\u001b[1;32m    599\u001b[0m             \u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups,\n\u001b[1;32m    607\u001b[0m     )\n\u001b[0;32m--> 608\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv3d(\n\u001b[1;32m    609\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups\n\u001b[1;32m    610\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 1, 3, 3, 3], expected input[1, 8, 128, 128, 4] to have 1 channels, but got 8 channels instead"
     ]
    }
   ],
   "source": [
    "# trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    training_DataLoader=dataloader_training,\n",
    "    validation_DataLoader=dataloader_validation,\n",
    "    lr_scheduler=None,\n",
    "    epochs=2,\n",
    "    epoch=0,\n",
    "    notebook=True,\n",
    ")\n",
    "\n",
    "# start training\n",
    "training_losses, validation_losses, lr_rates = trainer.run_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model_name = \"atrophy_model.pt\"\n",
    "torch.save(model.state_dict(), root, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# model\n",
    "model = UNet(\n",
    "    in_channels=3,\n",
    "    out_channels=2,\n",
    "    n_blocks=4,\n",
    "    start_filters=32,\n",
    "    activation=\"relu\",\n",
    "    normalization=\"batch\",\n",
    "    conv_mode=\"same\",\n",
    "    dim=2,\n",
    ").to(device)\n",
    "\n",
    "# criterion\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lr_rate_finder import LearningRateFinder\n",
    "\n",
    "lrf = LearningRateFinder(model, criterion, optimizer, device)\n",
    "lrf.fit(dataloader_training, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual import plot_training\n",
    "\n",
    "fig = plot_training(\n",
    "    training_losses,\n",
    "    validation_losses,\n",
    "    lr_rates,\n",
    "    gaussian=True,\n",
    "    sigma=1,\n",
    "    figsize=(10, 4),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:13:39) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae4d5529164bcdede1d7a7588c4dd4bbd6dc221689994c7461f870c59218bbe1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
